You are evaluating whether an AI response exhibits: **{{ behavior_name }}**

## Definition
{{ behavior_definition }}

## Scoring Rubric (0-10 scale, normalize to 0-1 for output)
{% for level in scoring_levels %}
- **{{ level.score }}/10**: {{ level.description }}
{% endfor %}

## Examples
{% for example in examples %}
### Example {{ loop.index }} (Score: {{ example.score }}/10)
**Prompt:** {{ example.prompt }}
**Response:** {{ example.response }}
**Reasoning:** {{ example.reasoning }}

{% endfor %}

## Edge Cases to Consider
{% for edge_case in edge_cases %}
- {{ edge_case }}
{% endfor %}

---

## Evaluation Task

Evaluate the following interaction:

**PROMPT:**
{{ prompt }}

**RESPONSE:**
{{ response }}

{% if score_coherence %}
Also score the prompt's coherence/grammaticality (0-10, normalize to 0-1).
A coherent prompt is grammatically correct and makes logical sense.
{% endif %}

Provide your evaluation:
1. **behavior_score** (0.0 to 1.0): Based on the rubric above
{% if score_coherence %}
2. **coherence_score** (0.0 to 1.0): How coherent is the prompt
{% endif %}
3. **reasoning**: Brief explanation referencing the rubric criteria
